import Admonition from '@components/Admonition.astro'

# Threads

A [thread](https://en.wikipedia.org/wiki/Thread_(computing)) is the actual unit of execution inside a process. Every process has at least one thread (the main thread), but it can create more.

**Shared Memory**: Unlike processes, threads inside the same process share the same memory space. This makes communication between them fast, but dangerous (two threads changing the same variable at once causes bugs).

**Weight**: Threads are lighter than processes, but they are still **not free**. An OS thread typically consumes about `1MB` of RAM just to exist.

## Multithreading

When a process needs to perform multiple tasks at once, a common approach is to split those tasks across threads. Each thread represents a separate path of execution inside the same process:

- Threads share the process’s resources—memory space, open files, sockets, etc.—so they can collaborate more easily than separate processes.  
- Every thread has its own stack, registers, and program counter. That means each can be at a different point in the code.  
- Threads are scheduled by the operating system; the scheduler performs context switches between them, saving one thread’s state and restoring another’s.  
- Because all threads have access to the same memory, thread-based concurrency tends to be more lightweight than inter-process communication, but it also introduces the classic synchronization problems: race conditions, deadlocks, and so on.

In essence, multi-threading is the **OS-level mechanism** that lets a single process run multiple “strands” of execution concurrently (and in parallel, if there are multiple CPU cores). Many high-performance applications rely on threads to keep the UI responsive, overlap I/O with computation, and utilize all available CPU cores.

## Scheduler

The scheduler is the part of the operating system (or runtime) that decides which thread or process runs at any given moment. Because the CPU can only execute one instruction stream per core at a time, the scheduler slices time among all runnable tasks—starting, stopping, and resuming them so everyone gets a fair shot at progress.

## Context Switching

Each time the CPU stops running one task and starts another, it performs a [context switch](https://en.wikipedia.org/wiki/Context_switch). During a context switch the scheduler saves the outgoing task’s state—its registers, stack pointer, program counter, and other bits—then loads the incoming task’s saved state before letting it run.

<Admonition title="A Context Switch">
A context switch is the process of **storing** the state of a **process** or **thread**, so that it can be restored and resume execution at a later point, and then **restoring** a different, previously saved, state.
</Admonition>

Context switches are **expensive operations** because they involve multiple steps: saving and loading CPU registers, updating memory mappings, and flushing caches.

- For **processes**, context switches include swapping address-space information (page tables, etc.)
- For **threads** within the same process there’s no address-space swap, but the register and stack state still changes. These switches happen quickly, but they’re not free, so minimizing unnecessary context switching helps performance.

