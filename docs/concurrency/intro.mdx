import Admonition from '@components/Admonition.astro'

# Concurrency

When we build software that serves real users, our systems rarely handle one thing at a time. Consider a **web server**: multiple clients send requests nearly simultaneously, each wants a response quickly, and each request might read from or write to **shared resources** such as in-memory caches, log files, or database connections.

If the server simply handled requests **sequentially** (waiting for one request to complete before starting the next) users would experience slow responses, having to wait inline before previous requests are dispatched. This is exacerbated because accessing shared resources often involves **slow operations** (like disk access or network calls) that would block everyone else.

These problems are not limited to web servers. Any system that handles multiple tasks needs to solve the same problems: keep many tasks making progress, manage access to shared resources, and do whatever it has to be done to respond quickly.

<Admonition title="Concurrency">
  [Concurrency](https://en.wikipedia.org/wiki/Concurrency_(computer_science)) is
  the ability of a system to perform multiple tasks at the same time. These
  tasks can access **shared resources**, such as memory or files, and may need
  to be synchronized to avoid conflicts. They also can **communicate** with each
  other to exchange data or coordinate their actions.
</Admonition>

In Go, concurrency is a **first-class citizen**, meaning that the language includes some built-in constructs, that make it easy to write programs that can perform multiple operations simultaneously.

## Concurrency vs. Parallelism

When solving these challenges in a non-sequential way, we can differentiate between two main approaches:

- **Concurrency** solves this issue having **one worker** switching between tasks so fast it looks like they are happening simultaneously.

  For example, the **JavaScript runtime** is single-threaded but highly concurrent via its event loop; it interleaves tasks without parallel execution. The system starts **Task A** (e.g. sending an HTTP request), pauses it to work on **Task B** (e.g. handling a button click), then goes back to Task A. They "overlap" in timeframe, but only one is actually moving forward at any specific nanosecond.

- **Parallelism** solves it by having **multiple workers** doing different tasks at the exact same time.

  For example, in languages like **Go**, you can spawn multiple goroutines that run truly in parallel on different CPU cores. Here, **Task A** and **Task B** can both be actively progressing at the same time, each on its own thread of execution.

<Admonition title="Both Concurrency and Parallelism">
  Many languages utilize both concepts. For example, JavaScript achieves
  **concurrency** via the *Event Loop* (handling multiple tasks on a single
  thread) but opts into **parallelism** using *Worker Threads* (executing code
  simultaneously on separate CPU cores).
</Admonition>

Go simplifies this by blending both behaviors into a single primitive: the [Goroutine](https://go.dev/tour/concurrency/1).

## Utilizing Multiple CPU Cores

Modern hardware architectures are built with [multiple cores](https://en.wikipedia.org/wiki/Multi-core_processor), so it make sense that programming languages offer a way to fully utilize the capabilities of a machine.

![multicore](./img/single-vs-multiple.webp)

Using **concurrent programming** we can split our program's workload into tasks, that can run simultaneously in multiple CPU cores. This increases the throughput of our programs, and speeds up their execution.

## Single Core Benefits

Even with a **single CPU core**, concurrency offers benefits. Most programs spend only a small proportion of their time executing computations on the processor. The majority of the time, the CPU is waiting on **slow I/O** (disk, network, user input). Instead of letting the core sit idle during those waits, concurrent programs can switch to other tasks that are ready to run, making better use of the CPU time.

<Admonition type="info" title="Real-life analogy">
  Imagine you're baking some muffins. While they are in the oven, you can be
  doing the dishes, or start another batch. Instead of sitting iddle, just
  waiting for the muffins to bake, you're using that time to get other things
  done.
</Admonition>

JavaScript is a well-known example: the language doesnâ€™t expose primitives for splitting work across multiple CPU cores, yet its event loop and callback mechanism let it juggle many asynchronous tasks without blocking the page.
